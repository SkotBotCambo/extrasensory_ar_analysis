{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import importlib.machinery\n",
    "import sys\n",
    "sys.path.append('/home/sac086/extrasensory/')\n",
    "import extrasense as es\n",
    "from sklearn.metrics import accuracy_score, make_scorer, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Imputer\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_df = es.get_impersonal_data(leave_users_out=[], drop_nan_rows=False, sensors=None, label_type=\"activity\", labeled_only=True)\n",
    "\n",
    "timestamps = features_df.pop('timestamp')\n",
    "label_source = features_df.pop(\"label_source\")\n",
    "labels = features_df.pop(\"label\")\n",
    "user_ids = features_df.pop(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in labels.unique():\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = es.get_uids_from_es_folds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_baseline_model():\n",
    "    steps = []\n",
    "    steps.append(('imputer', Imputer(missing_values='NaN', strategy='mean', axis=0)))\n",
    "    steps.append(('standardize', StandardScaler()))\n",
    "    steps.append(('clf', LogisticRegression(class_weight='balanced')))\n",
    "    model = Pipeline(steps)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pipeline(clf, **params):\n",
    "    steps = []\n",
    "    steps.append(('imputer', Imputer(missing_values='NaN', strategy='mean', axis=0)))\n",
    "    steps.append(('standardize', StandardScaler()))\n",
    "    steps.append(('clf', clf(params)))\n",
    "    model = Pipeline(steps)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_test_ind(test_fold_uids, all_user_ids):\n",
    "    bool_arr = all_user_ids.isin(test_fold_uids)\n",
    "    test_ind = all_user_ids.index[bool_arr]\n",
    "    bool_arr = np.logical_not(bool_arr)\n",
    "    train_ind = all_user_ids.index[bool_arr]\n",
    "    return train_ind, test_ind\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metrics(y, y_pred, verbose=True):\n",
    "    predictions = []\n",
    "    # Naive accuracy (correct classification rate):\n",
    "    accuracy = np.mean(y_pred == y);\n",
    "    \n",
    "    # Count occorrences of true-positive, true-negative, false-positive, and false-negative:\n",
    "    tp = np.sum(np.logical_and(y_pred,y));\n",
    "    tn = np.sum(np.logical_and(np.logical_not(y_pred),np.logical_not(y)));\n",
    "    fp = np.sum(np.logical_and(y_pred,np.logical_not(y)));\n",
    "    fn = np.sum(np.logical_and(np.logical_not(y_pred),y));\n",
    "    \n",
    "    # Sensitivity (=recall=true positive rate) and Specificity (=true negative rate):\n",
    "    sensitivity = float(tp) / (tp+fn);\n",
    "    specificity = float(tn) / (tn+fp);\n",
    "    \n",
    "    # Balanced accuracy is a more fair replacement for the naive accuracy:\n",
    "    balanced_accuracy = (sensitivity + specificity) / 2.;\n",
    "    \n",
    "    # Precision:\n",
    "    # Beware from this metric, since it may be too sensitive to rare labels.\n",
    "    # In the ExtraSensory Dataset, there is large skew among the positive and negative classes,\n",
    "    # and for each label the pos/neg ratio is different.\n",
    "    # This can cause undesirable and misleading results when averaging precision across different labels.\n",
    "    precision = float(tp) / (tp+fp);\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"-\"*10);\n",
    "        print('Accuracy*:         %.2f' % accuracy);\n",
    "        print('Sensitivity (TPR): %.2f' % sensitivity);\n",
    "        print('Specificity (TNR): %.2f' % specificity);\n",
    "        print('Balanced accuracy: %.2f' % balanced_accuracy);\n",
    "        print('Precision**:       %.2f' % precision);\n",
    "        print(\"-\"*10);\n",
    "        \n",
    "    return {'sensitivity' : sensitivity,\n",
    "            'specificity' : specificity,\n",
    "            'accuracy' : accuracy,\n",
    "            'balanced accuracy' : balanced_accuracy,\n",
    "            'precision' : precision}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(model_getter, context, **params):\n",
    "    folds = es.get_uids_from_es_folds()\n",
    "    fold_metrics = []\n",
    "    \n",
    "    for i, kf in enumerate(folds):\n",
    "        print('Fold #%s' % i)\n",
    "        model = model_getter(**params)\n",
    "        \n",
    "        train_ind, test_ind = get_train_test_ind(kf, user_ids)\n",
    "        \n",
    "        print(\"Training model...\")\n",
    "        X_train = features_df.iloc[train_ind]\n",
    "        y_train = labels.iloc[train_ind]\n",
    "        y_train = np.array([1 if y == context else 0 for y in y_train])\n",
    "        \n",
    "        X_test = features_df.iloc[test_ind]\n",
    "        y_test = labels.iloc[test_ind]\n",
    "        y_test = np.array([1 if y == context else 0 for y in y_test])\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"Testing model...\")\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        metrics = get_metrics(y_test, y_pred, verbose=True)\n",
    "        fold_metrics.append(metrics)\n",
    "    \n",
    "    return fold_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #0\n",
      "Training model...\n",
      "Testing model...\n",
      "----------\n",
      "Accuracy*:         0.78\n",
      "Sensitivity (TPR): 0.82\n",
      "Specificity (TNR): 0.74\n",
      "Balanced accuracy: 0.78\n",
      "Precision**:       0.73\n",
      "----------\n",
      "Fold #1\n",
      "Training model...\n",
      "Testing model...\n",
      "----------\n",
      "Accuracy*:         0.74\n",
      "Sensitivity (TPR): 0.83\n",
      "Specificity (TNR): 0.67\n",
      "Balanced accuracy: 0.75\n",
      "Precision**:       0.67\n",
      "----------\n",
      "Fold #2\n",
      "Training model...\n",
      "Testing model...\n",
      "----------\n",
      "Accuracy*:         0.78\n",
      "Sensitivity (TPR): 0.77\n",
      "Specificity (TNR): 0.78\n",
      "Balanced accuracy: 0.78\n",
      "Precision**:       0.73\n",
      "----------\n",
      "Fold #3\n",
      "Training model...\n",
      "Testing model...\n",
      "----------\n",
      "Accuracy*:         0.77\n",
      "Sensitivity (TPR): 0.72\n",
      "Specificity (TNR): 0.79\n",
      "Balanced accuracy: 0.76\n",
      "Precision**:       0.69\n",
      "----------\n",
      "Fold #4\n",
      "Training model...\n",
      "Testing model...\n",
      "----------\n",
      "Accuracy*:         0.67\n",
      "Sensitivity (TPR): 0.68\n",
      "Specificity (TNR): 0.67\n",
      "Balanced accuracy: 0.67\n",
      "Precision**:       0.68\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "test_metrics = test_model(get_baseline_model, 'SITTING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_metrics(metrics, verbose=True):\n",
    "    mean_metrics = {}\n",
    "    \n",
    "    for fold_metrics in metrics:\n",
    "        for key, val in fold_metrics.items():\n",
    "            if key in mean_metrics:\n",
    "                mean_metrics[key].append(val)\n",
    "            else:\n",
    "                mean_metrics[key] = [val]\n",
    "    \n",
    "    print(\"-\"*10);\n",
    "    print('Accuracy*:         %.2f' % np.mean(mean_metrics['accuracy']));\n",
    "    print('Sensitivity (TPR): %.2f' % np.mean(mean_metrics['sensitivity']));\n",
    "    print('Specificity (TNR): %.2f' % np.mean(mean_metrics['specificity']))\n",
    "    print('Balanced accuracy: %.2f' % np.mean(mean_metrics['balanced accuracy']))\n",
    "    print('Precision**:       %.2f' % np.mean(mean_metrics['precision']))\n",
    "    print(\"-\"*10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Accuracy*:         0.75\n",
      "Sensitivity (TPR): 0.77\n",
      "Specificity (TNR): 0.73\n",
      "Balanced accuracy: 0.75\n",
      "Precision**:       0.70\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "get_mean_metrics(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BICYCLING : 5020\n",
      "SITTING : 136728\n",
      "LYING_DOWN : 141461\n",
      "STAIRS : 822\n",
      "FIX_walking : 22136\n",
      "FIX_running : 1090\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter(labels)\n",
    "for key, val in c.items():\n",
    "    print(\"%s : %s\" % (key, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_xgb_model():\n",
    "    steps = []\n",
    "    steps.append(('standardize', StandardScaler()))\n",
    "    steps.append(('clf', xgb.XGBClassifier()))\n",
    "    model = Pipeline(steps)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #0\n",
      "Training model...\n",
      "Testing model...\n",
      "----------\n",
      "Accuracy*:         0.67\n",
      "Sensitivity (TPR): 0.62\n",
      "Specificity (TNR): 0.72\n",
      "Balanced accuracy: 0.67\n",
      "Precision**:       0.66\n",
      "----------\n",
      "Fold #1\n",
      "Training model...\n",
      "Testing model...\n",
      "----------\n",
      "Accuracy*:         0.66\n",
      "Sensitivity (TPR): 0.59\n",
      "Specificity (TNR): 0.71\n",
      "Balanced accuracy: 0.65\n",
      "Precision**:       0.63\n",
      "----------\n",
      "Fold #2\n",
      "Training model...\n",
      "Testing model...\n",
      "----------\n",
      "Accuracy*:         0.70\n",
      "Sensitivity (TPR): 0.64\n",
      "Specificity (TNR): 0.75\n",
      "Balanced accuracy: 0.69\n",
      "Precision**:       0.66\n",
      "----------\n",
      "Fold #3\n",
      "Training model...\n",
      "Testing model...\n",
      "----------\n",
      "Accuracy*:         0.69\n",
      "Sensitivity (TPR): 0.67\n",
      "Specificity (TNR): 0.70\n",
      "Balanced accuracy: 0.69\n",
      "Precision**:       0.59\n",
      "----------\n",
      "Fold #4\n",
      "Training model...\n",
      "Testing model...\n",
      "----------\n",
      "Accuracy*:         0.59\n",
      "Sensitivity (TPR): 0.61\n",
      "Specificity (TNR): 0.58\n",
      "Balanced accuracy: 0.59\n",
      "Precision**:       0.60\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "test_metrics = test_model(get_xgb_model, 'SITTING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Accuracy*:         0.66\n",
      "Sensitivity (TPR): 0.62\n",
      "Specificity (TNR): 0.69\n",
      "Balanced accuracy: 0.66\n",
      "Precision**:       0.63\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "get_mean_metrics(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sensor Fusion\n",
    "* This is from the [Recognizing Detailed Human Context-In-the-Wild from Smartphones and Smartwatches](http://extrasensory.ucsd.edu/papers/vaizman2017a_pervasiveAcceptedVersion.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SensorFusionClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Late Fusion Using Average Probability\n",
    "    \n",
    "    Attributes: \n",
    "    clf: The base classifier to use for the individual classifiers\n",
    "    \"\"\"\n",
    "    \n",
    "    base_clf = None\n",
    "    base_params=None\n",
    "    classifiers = {}\n",
    "    sensors = []\n",
    "    training_accuracy = None\n",
    "    verbose=True\n",
    "    confidence_threshold = None\n",
    "    \n",
    "    def __init__(self, base_clf=None, confidence_threshold=0.5, sensors=None, base_params={}):\n",
    "        args, _, _, values = inspect.getargvalues(inspect.currentframe())\n",
    "        for arg, val in values.items():\n",
    "            setattr(self, arg, val)\n",
    "        if self.base_clf is None:\n",
    "            self.base_clf = LogisticRegression\n",
    "                \n",
    "        if confidence_threshold is not None:\n",
    "            self.confidence_threshold = confidence_threshold\n",
    "    \n",
    "    def fit(self, X_train, y_train, sensors=None):\n",
    "        if sensors:\n",
    "            self.sensors = sensors\n",
    "        \n",
    "        for sensor in self.sensors:\n",
    "            if self.verbose:\n",
    "                print(\"Training classifier with data from %s sensor\" % sensor)\n",
    "            X_train_sensor = self.get_features_for_sensor(X_train, sensor)\n",
    "            clf_sensor = make_pipeline(self.base_clf, params=self.base_params)\n",
    "            clf_sensor.fit(X_train_sensor, y_train)\n",
    "            self.classifiers[sensor] = clf_sensor\n",
    "        \n",
    "    def get_features_for_sensor(self,X, sensor):\n",
    "        feature_cols = []\n",
    "        \n",
    "        for col in X.columns:\n",
    "            sensor_names = es.sensor_key_dict[sensor]\n",
    "            for sensor_name in sensor_names:\n",
    "                if sensor_name in col:\n",
    "                    feature_cols.append(col)\n",
    "                    break\n",
    "        \n",
    "        return X[X.columns.intersection(feature_cols)]\n",
    "    \n",
    "    def predict(self, X_test, sensors=None, fusion_type='late_averaging'):\n",
    "        if sensors is None:\n",
    "            sensors = self.sensors\n",
    "        y_pred = self.get_predictions(X_test,sensors=sensors)\n",
    "        \n",
    "        if fusion_type is 'late_averaging':\n",
    "            # average across rows\n",
    "            y_mean_pred = y_pred.mean(axis=1)\n",
    "            y_pred = y_mean_pred > self.confidence_threshold # may have to convert this from boolean to integer 1,0\n",
    "            return y_pred.astype(int)\n",
    "\n",
    "    def get_predictions(self, X_test,sensors=None):\n",
    "        if sensors == None:\n",
    "            prediction_sensors = self.sensors\n",
    "        else:\n",
    "            prediction_sensors = sensors\n",
    "        \n",
    "        predictions_by_classifier = {}\n",
    "        \n",
    "        for sensor in prediction_sensors:\n",
    "            X_test_sensor = self.get_features_for_sensor(X_test, sensor)\n",
    "            predictions = self.classifiers[sensor].predict_proba(X_test_sensor)[:,1]\n",
    "            predictions_by_classifier[sensor] = pd.Series(predictions, name=sensor)\n",
    "\n",
    "        predictions_df = pd.concat([p for p in predictions_by_classifier.values()], axis=1)\n",
    "        \n",
    "        return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SensorFusionClassifier(sensors=[\"Acc\", \"Gyro\", \"Magnet\", \"WAcc\", \"Compass\", \"Loc\", \"Aud\", \"AP\", \"PS\", \"LF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_ind, test_ind = get_train_test_ind(folds[0], user_ids)\n",
    "\n",
    "print(\"Training model...\")\n",
    "X_train = features_df.iloc[train_ind]\n",
    "y_train = labels.iloc[train_ind]\n",
    "y_train = np.array([1 if y == context else 0 for y in y_train])\n",
    "\n",
    "X_test = features_df.iloc[test_ind]\n",
    "y_test = labels.iloc[test_ind]\n",
    "y_test = np.array([1 if y == context else 0 for y in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier with data from Acc sensor\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-48a2aac41443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-924dbc2e7060>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, sensors)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mX_train_sensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features_for_sensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mclf_sensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mclf_sensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_sensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_sensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1231\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m     \u001b[0msolver_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_liblinear_solver_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m     raw_coef_, n_iter_ = liblinear.train_wrap(\n\u001b[1;32m    888\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_get_liblinear_solver_type\u001b[0;34m(multi_class, penalty, loss, dual)\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0merror_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"loss='%s' is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0m_solver_dual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_solver_pen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_solver_dual\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             error_string = (\"The combination of penalty='%s' \"\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ^^^^ Need to figure out how sklearn manages *args, **kwargs, **params, that kind of thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use LFA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #0\n",
      "Training model...\n",
      "Training classifier with data from Acc sensor\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'LogisticRegression' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-0817f8441ab8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSensorFusionClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SITTING'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Acc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Gyro\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Magnet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"WAcc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Compass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Loc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Aud\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"LF\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-837e5914833a>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model_getter, context, **params)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-7057b7e101b4>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, sensors)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training classifier with data from %s sensor\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mX_train_sensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features_for_sensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mclf_sensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mclf_sensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_sensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_sensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-f220c1132435>\u001b[0m in \u001b[0;36mmake_pipeline\u001b[0;34m(clf, **params)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imputer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NaN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'standardize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'LogisticRegression' object is not callable"
     ]
    }
   ],
   "source": [
    "test_metrics = test_model(SensorFusionClassifier, 'SITTING',sensors=[\"Acc\", \"Gyro\", \"Magnet\", \"WAcc\", \"Compass\", \"Loc\", \"Aud\", \"AP\", \"PS\", \"LF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Accuracy*:         0.63\n",
      "Sensitivity (TPR): 0.41\n",
      "Specificity (TNR): 0.80\n",
      "Balanced accuracy: 0.61\n",
      "Precision**:       0.63\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "get_mean_metrics(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
