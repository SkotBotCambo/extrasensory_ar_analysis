{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import importlib.machinery\n",
    "es = importlib.machinery.SourceFileLoader('extrasense','/home/sac086/extrasensory/extrasense/extrasense.py').load_module()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, ShuffleSplit, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreating Exp1\n",
    "\n",
    "**Experimental Conditions**: Impersonal, Personal, Hybrid training data\n",
    "\n",
    "**Experiment Output**: User ID, Method, Run number, Accuracy\n",
    "\n",
    "**Sampling Method for personal data**: randomly sample the data, no stratification of sample classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%px\n",
    "def run_experiment1(user_id):\n",
    "    personal_df = es.get_data_from_user_id(user_id, data_type=\"activity\", labeled_only=True)\n",
    "    timestamps_personal = personal_df.pop('timestamp')\n",
    "    \n",
    "    # train impersonal model\n",
    "    impersonal_df = es.get_impersonal_data(user_id, data_type=\"activity\", labeled_only=True)\n",
    "    timestamps_impersonal = impersonal_df.pop('timestamp')\n",
    "    impersonal_train_labels = impersonal_df.pop(\"label\")\n",
    "\n",
    "     # standard scale training\n",
    "    impersonal_scaler = StandardScaler().fit(impersonal_df)\n",
    "    scaled_impersonal_df = impersonal_scaler.transform(impersonal_df)\n",
    "    \n",
    "    impersonal_clf = RandomForestClassifier()\n",
    "    impersonal_clf.fit(scaled_impersonal_df, impersonal_train_labels)\n",
    "    \n",
    "    # setup sampler\n",
    "    rs = ShuffleSplit(n_splits=5, test_size=100)\n",
    "    \n",
    "    run_count = 1\n",
    "    rows = []\n",
    "    # run sampler    \n",
    "    for train_ind, test_ind in rs.split(personal_df):\n",
    "        personal_train_df = personal_df.iloc[train_ind]\n",
    "        personal_train_labels = personal_train_df.pop(\"label\")\n",
    "        \n",
    "        val_df = personal_df.iloc[test_ind]\n",
    "        val_labels = val_df.pop(\"label\")\n",
    "        \n",
    "        #return personal_train_df, personal_train_labels, impersonal_df, impersonal_train_labels\n",
    "        hybrid_train_df = pd.concat([impersonal_df, personal_train_df])\n",
    "        hybrid_train_labels = pd.concat([impersonal_train_labels, personal_train_labels])\n",
    "        \n",
    "        # scale \n",
    "        personal_scaler = StandardScaler().fit(personal_train_df)\n",
    "        scaled_personal_df = personal_scaler.transform(personal_train_df)\n",
    "        \n",
    "        hybrid_scaler = StandardScaler().fit(hybrid_train_df)\n",
    "        scaled_hybrid_df = hybrid_scaler.transform(hybrid_train_df)\n",
    "        \n",
    "        # build and predict personal model\n",
    "        personal_clf = RandomForestClassifier()\n",
    "        personal_clf.fit(scaled_personal_df, personal_train_labels)\n",
    "        personal_scaled_val_df = personal_scaler.transform(val_df)\n",
    "        personal_predictions = personal_clf.predict(personal_scaled_val_df)\n",
    "        \n",
    "        # build and predict hybrid model\n",
    "        hybrid_clf = RandomForestClassifier()\n",
    "        hybrid_clf.fit(scaled_hybrid_df, hybrid_train_labels)\n",
    "        hybrid_scaled_val_df = hybrid_scaler.transform(val_df)\n",
    "        hybrid_predictions = hybrid_clf.predict(hybrid_scaled_val_df)\n",
    "        \n",
    "        # impersonal predictions\n",
    "        impersonal_scaled_val_df = impersonal_scaler.transform(val_df)\n",
    "        impersonal_predictions = impersonal_clf.predict(impersonal_scaled_val_df)\n",
    "        \n",
    "        # validate models\n",
    "        personal_score = accuracy_score(val_labels, personal_predictions)\n",
    "        hybrid_score = accuracy_score(val_labels, hybrid_predictions)\n",
    "        impersonal_score = accuracy_score(val_labels, impersonal_predictions)\n",
    "        \n",
    "        print(\"\\tRun #%s\" % run_count)\n",
    "        print(\"\\tpersonal : %s\" % personal_score)\n",
    "        print(\"\\thybrid : %s\" % hybrid_score)\n",
    "        print(\"\\timpersonal : %s\" % impersonal_score)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        personal_row = {\"user_id\" : user_id, \n",
    "                        \"method\":\"personal\", \n",
    "                        \"run_num\" : run_count,\n",
    "                        \"accuracy\" : personal_score}\n",
    "        \n",
    "        hybrid_row = {\"user_id\" : user_id, \n",
    "                        \"method\":\"hybrid\", \n",
    "                        \"run_num\" : run_count,\n",
    "                        \"accuracy\" : hybrid_score}\n",
    "        \n",
    "        impersonal_row = {\"user_id\" : user_id, \n",
    "                        \"method\":\"impersonal\", \n",
    "                        \"run_num\" : run_count,\n",
    "                        \"accuracy\" : impersonal_score}\n",
    "        rows.append(personal_row)\n",
    "        rows.append(hybrid_row)\n",
    "        rows.append(impersonal_row)\n",
    "        \n",
    "        run_count += 1\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for user_id in es.user_ids:\n",
    "    print(\"Getting scores for %s\" % user_id)\n",
    "    start = time.time()\n",
    "    user_rows = run_experiment1(user_id)\n",
    "    finish = time.time()\n",
    "    duration_in_minutes = (finish - start) / 60.\n",
    "    print(\"\\ttook %s minutes\" % (duration_in_minutes))\n",
    "    rows += user_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_df.to_pickle('./scores_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df[scores_df['method'] == 'personal'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df[scores_df['method'] == 'impersonal'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(es.user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "personal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impersonal_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying Stratified Shuffle with parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ipyparallel as ipp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = ipp.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dview = c[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dview.block=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dview.scatter('user_ids', es.user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import_string = '''import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import importlib.machinery\n",
    "es = importlib.machinery.SourceFileLoader('extrasense','/home/sac086/extrasensory/extrasense/extrasense.py').load_module()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, ShuffleSplit, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "asr = dview.execute(import_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "def run_experiment1(user_id, stratified=False):\n",
    "    personal_df = es.get_data_from_user_id(user_id, data_type=\"activity\", labeled_only=True)\n",
    "    timestamps_personal = personal_df.pop('timestamp')\n",
    "    personal_labels = personal_df.pop(\"label\")\n",
    "\n",
    "    # train impersonal model\n",
    "    impersonal_df = es.get_impersonal_data(user_id, data_type=\"activity\", labeled_only=True)\n",
    "    timestamps_impersonal = impersonal_df.pop('timestamp')\n",
    "    impersonal_train_labels = impersonal_df.pop(\"label\")\n",
    "\n",
    "     # standard scale training\n",
    "    impersonal_scaler = StandardScaler().fit(impersonal_df)\n",
    "    scaled_impersonal_df = impersonal_scaler.transform(impersonal_df)\n",
    "    \n",
    "    impersonal_clf = RandomForestClassifier()\n",
    "    impersonal_clf.fit(scaled_impersonal_df, impersonal_train_labels)\n",
    "    \n",
    "    # setup sampler\n",
    "    if stratified:\n",
    "        rs = StratifiedShuffleSplit(n_splits=5, train_size=10, test_size=100)\n",
    "        split_iterator = rs.split(personal_df, personal_labels)\n",
    "    else:\n",
    "        rs = ShuffleSplit(n_splits=5, train_size=10, test_size=100)\n",
    "        split_iterator = rs.split(personal_df)\n",
    "    run_count = 1\n",
    "    rows = []\n",
    "    # run sampler    \n",
    "    for train_ind, test_ind in split_iterator:\n",
    "        personal_train_df = personal_df.iloc[train_ind]\n",
    "        personal_train_labels = personal_labels.iloc[train_ind]\n",
    "        \n",
    "        val_df = personal_df.iloc[test_ind]\n",
    "        val_labels = personal_labels.iloc[test_ind]\n",
    "        \n",
    "        #return personal_train_df, personal_train_labels, impersonal_df, impersonal_train_labels\n",
    "        hybrid_train_df = pd.concat([impersonal_df, personal_train_df])\n",
    "        hybrid_train_labels = pd.concat([impersonal_train_labels, personal_train_labels])\n",
    "        \n",
    "        # scale \n",
    "        personal_scaler = StandardScaler().fit(personal_train_df)\n",
    "        scaled_personal_df = personal_scaler.transform(personal_train_df)\n",
    "        \n",
    "        hybrid_scaler = StandardScaler().fit(hybrid_train_df)\n",
    "        scaled_hybrid_df = hybrid_scaler.transform(hybrid_train_df)\n",
    "        \n",
    "        # build and predict personal model\n",
    "        personal_clf = RandomForestClassifier()\n",
    "        personal_clf.fit(scaled_personal_df, personal_train_labels)\n",
    "        personal_scaled_val_df = personal_scaler.transform(val_df)\n",
    "        personal_predictions = personal_clf.predict(personal_scaled_val_df)\n",
    "        \n",
    "        # build and predict hybrid model\n",
    "        hybrid_clf = RandomForestClassifier()\n",
    "        hybrid_clf.fit(scaled_hybrid_df, hybrid_train_labels)\n",
    "        hybrid_scaled_val_df = hybrid_scaler.transform(val_df)\n",
    "        hybrid_predictions = hybrid_clf.predict(hybrid_scaled_val_df)\n",
    "        \n",
    "        # impersonal predictions\n",
    "        impersonal_scaled_val_df = impersonal_scaler.transform(val_df)\n",
    "        impersonal_predictions = impersonal_clf.predict(impersonal_scaled_val_df)\n",
    "        \n",
    "        # validate models\n",
    "        personal_score = accuracy_score(val_labels, personal_predictions)\n",
    "        hybrid_score = accuracy_score(val_labels, hybrid_predictions)\n",
    "        impersonal_score = accuracy_score(val_labels, impersonal_predictions)\n",
    "        \n",
    "        print(\"\\tRun #%s\" % run_count)\n",
    "        print(\"\\tpersonal : %s\" % personal_score)\n",
    "        print(\"\\thybrid : %s\" % hybrid_score)\n",
    "        print(\"\\timpersonal : %s\" % impersonal_score)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        personal_row = {\"user_id\" : user_id, \n",
    "                        \"method\":\"personal\", \n",
    "                        \"run_num\" : run_count,\n",
    "                        \"accuracy\" : personal_score}\n",
    "        \n",
    "        hybrid_row = {\"user_id\" : user_id, \n",
    "                        \"method\":\"hybrid\", \n",
    "                        \"run_num\" : run_count,\n",
    "                        \"accuracy\" : hybrid_score}\n",
    "        \n",
    "        impersonal_row = {\"user_id\" : user_id, \n",
    "                        \"method\":\"impersonal\", \n",
    "                        \"run_num\" : run_count,\n",
    "                        \"accuracy\" : impersonal_score}\n",
    "        rows.append(personal_row)\n",
    "        rows.append(hybrid_row)\n",
    "        rows.append(impersonal_row)\n",
    "        \n",
    "        run_count += 1\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without class stratification\n",
    "\n",
    "command1 = '''\n",
    "rows = []\n",
    "errors = []\n",
    "\n",
    "for user_id in user_ids:\n",
    "    print(\"Getting scores for %s\" % user_id)\n",
    "    start = time.time()\n",
    "    try:\n",
    "        user_rows = run_experiment1(user_id)\n",
    "    except ValueError as ve:\n",
    "        errors.append(ve)\n",
    "        continue\n",
    "    finish = time.time()\n",
    "    duration_in_minutes = (finish - start) / 60.\n",
    "    print(\"\\ttook %s minutes\" % (duration_in_minutes))\n",
    "    rows += user_rows\n",
    "'''\n",
    "asr = dview.execute(command1)\n",
    "rows = dview.gather('rows')\n",
    "scores_df = pd.DataFrame(rows)\n",
    "scores_df.to_pickle('./scores_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# without class stratification\n",
    "\n",
    "command2 = '''\n",
    "rows = []\n",
    "errors = []\n",
    "\n",
    "for user_id in user_ids:\n",
    "    print(\"Getting scores for %s\" % user_id)\n",
    "    start = time.time()\n",
    "    try:\n",
    "        user_rows = run_experiment1(user_id, stratified=True)\n",
    "    except ValueError as ve:\n",
    "        errors.append(ve)\n",
    "        continue\n",
    "    finish = time.time()\n",
    "    duration_in_minutes = (finish - start) / 60.\n",
    "    print(\"\\ttook %s minutes\" % (duration_in_minutes))\n",
    "    rows += user_rows\n",
    "'''\n",
    "asr = dview.execute(command2)\n",
    "rows = dview.gather('rows')\n",
    "scores_df = pd.DataFrame(rows)\n",
    "scores_df.to_pickle('./scores_df_stratified.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the Impersonal Model really doing that good with a model that isn't even tuned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_df = es.get_impersonal_data(data_type=\"activity\", labeled_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>raw_acc:magnitude_stats:mean</th>\n",
       "      <th>raw_acc:magnitude_stats:std</th>\n",
       "      <th>raw_acc:magnitude_stats:moment3</th>\n",
       "      <th>raw_acc:magnitude_stats:moment4</th>\n",
       "      <th>raw_acc:magnitude_stats:percentile25</th>\n",
       "      <th>raw_acc:magnitude_stats:percentile50</th>\n",
       "      <th>raw_acc:magnitude_stats:percentile75</th>\n",
       "      <th>raw_acc:magnitude_stats:value_entropy</th>\n",
       "      <th>raw_acc:magnitude_stats:time_entropy</th>\n",
       "      <th>...</th>\n",
       "      <th>raw_acc:3d:mean_z</th>\n",
       "      <th>raw_acc:3d:std_x</th>\n",
       "      <th>raw_acc:3d:std_y</th>\n",
       "      <th>raw_acc:3d:std_z</th>\n",
       "      <th>raw_acc:3d:ro_xy</th>\n",
       "      <th>raw_acc:3d:ro_xz</th>\n",
       "      <th>raw_acc:3d:ro_yz</th>\n",
       "      <th>label</th>\n",
       "      <th>label_source</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>098A72A5-E3E5-4F54-A152-BBDA0DF7B694</td>\n",
       "      <td>1.019125</td>\n",
       "      <td>0.005488</td>\n",
       "      <td>-0.007333</td>\n",
       "      <td>0.012716</td>\n",
       "      <td>1.015712</td>\n",
       "      <td>1.018730</td>\n",
       "      <td>1.022642</td>\n",
       "      <td>1.534798</td>\n",
       "      <td>6.684597</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.018555</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>0.005455</td>\n",
       "      <td>0.231009</td>\n",
       "      <td>0.160268</td>\n",
       "      <td>0.274546</td>\n",
       "      <td>SITTING</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.438708e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>098A72A5-E3E5-4F54-A152-BBDA0DF7B694</td>\n",
       "      <td>1.027085</td>\n",
       "      <td>0.040910</td>\n",
       "      <td>0.065024</td>\n",
       "      <td>0.109432</td>\n",
       "      <td>1.021727</td>\n",
       "      <td>1.024658</td>\n",
       "      <td>1.027600</td>\n",
       "      <td>0.444923</td>\n",
       "      <td>6.683851</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.007858</td>\n",
       "      <td>0.129614</td>\n",
       "      <td>0.102002</td>\n",
       "      <td>0.105490</td>\n",
       "      <td>-0.538931</td>\n",
       "      <td>0.753075</td>\n",
       "      <td>-0.716014</td>\n",
       "      <td>SITTING</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.438709e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>098A72A5-E3E5-4F54-A152-BBDA0DF7B694</td>\n",
       "      <td>1.019498</td>\n",
       "      <td>0.034167</td>\n",
       "      <td>0.045501</td>\n",
       "      <td>0.098916</td>\n",
       "      <td>1.017684</td>\n",
       "      <td>1.019795</td>\n",
       "      <td>1.022740</td>\n",
       "      <td>0.493111</td>\n",
       "      <td>6.684059</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.015779</td>\n",
       "      <td>0.039070</td>\n",
       "      <td>0.074888</td>\n",
       "      <td>0.037067</td>\n",
       "      <td>0.126114</td>\n",
       "      <td>0.093632</td>\n",
       "      <td>0.414424</td>\n",
       "      <td>SITTING</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.438709e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>098A72A5-E3E5-4F54-A152-BBDA0DF7B694</td>\n",
       "      <td>1.014249</td>\n",
       "      <td>0.004560</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.010174</td>\n",
       "      <td>1.012491</td>\n",
       "      <td>1.013851</td>\n",
       "      <td>1.015850</td>\n",
       "      <td>1.387466</td>\n",
       "      <td>6.684602</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.013756</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.082769</td>\n",
       "      <td>-0.083428</td>\n",
       "      <td>0.147490</td>\n",
       "      <td>SITTING</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.438709e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>098A72A5-E3E5-4F54-A152-BBDA0DF7B694</td>\n",
       "      <td>1.015960</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.003965</td>\n",
       "      <td>0.007191</td>\n",
       "      <td>1.013798</td>\n",
       "      <td>1.015754</td>\n",
       "      <td>1.017733</td>\n",
       "      <td>1.646399</td>\n",
       "      <td>6.684606</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.015449</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.062909</td>\n",
       "      <td>0.083451</td>\n",
       "      <td>-0.049604</td>\n",
       "      <td>SITTING</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.438709e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                user_id  raw_acc:magnitude_stats:mean  \\\n",
       "0  098A72A5-E3E5-4F54-A152-BBDA0DF7B694                      1.019125   \n",
       "1  098A72A5-E3E5-4F54-A152-BBDA0DF7B694                      1.027085   \n",
       "2  098A72A5-E3E5-4F54-A152-BBDA0DF7B694                      1.019498   \n",
       "3  098A72A5-E3E5-4F54-A152-BBDA0DF7B694                      1.014249   \n",
       "4  098A72A5-E3E5-4F54-A152-BBDA0DF7B694                      1.015960   \n",
       "\n",
       "   raw_acc:magnitude_stats:std  raw_acc:magnitude_stats:moment3  \\\n",
       "0                     0.005488                        -0.007333   \n",
       "1                     0.040910                         0.065024   \n",
       "2                     0.034167                         0.045501   \n",
       "3                     0.004560                         0.002866   \n",
       "4                     0.003355                         0.003965   \n",
       "\n",
       "   raw_acc:magnitude_stats:moment4  raw_acc:magnitude_stats:percentile25  \\\n",
       "0                         0.012716                              1.015712   \n",
       "1                         0.109432                              1.021727   \n",
       "2                         0.098916                              1.017684   \n",
       "3                         0.010174                              1.012491   \n",
       "4                         0.007191                              1.013798   \n",
       "\n",
       "   raw_acc:magnitude_stats:percentile50  raw_acc:magnitude_stats:percentile75  \\\n",
       "0                              1.018730                              1.022642   \n",
       "1                              1.024658                              1.027600   \n",
       "2                              1.019795                              1.022740   \n",
       "3                              1.013851                              1.015850   \n",
       "4                              1.015754                              1.017733   \n",
       "\n",
       "   raw_acc:magnitude_stats:value_entropy  \\\n",
       "0                               1.534798   \n",
       "1                               0.444923   \n",
       "2                               0.493111   \n",
       "3                               1.387466   \n",
       "4                               1.646399   \n",
       "\n",
       "   raw_acc:magnitude_stats:time_entropy      ...       raw_acc:3d:mean_z  \\\n",
       "0                              6.684597      ...               -1.018555   \n",
       "1                              6.683851      ...               -1.007858   \n",
       "2                              6.684059      ...               -1.015779   \n",
       "3                              6.684602      ...               -1.013756   \n",
       "4                              6.684606      ...               -1.015449   \n",
       "\n",
       "   raw_acc:3d:std_x  raw_acc:3d:std_y  raw_acc:3d:std_z  raw_acc:3d:ro_xy  \\\n",
       "0          0.003047          0.003574          0.005455          0.231009   \n",
       "1          0.129614          0.102002          0.105490         -0.538931   \n",
       "2          0.039070          0.074888          0.037067          0.126114   \n",
       "3          0.003356          0.003058          0.004548          0.082769   \n",
       "4          0.002772          0.002371          0.003354          0.062909   \n",
       "\n",
       "   raw_acc:3d:ro_xz  raw_acc:3d:ro_yz    label  label_source     timestamp  \n",
       "0          0.160268          0.274546  SITTING           2.0  1.438708e+09  \n",
       "1          0.753075         -0.716014  SITTING           2.0  1.438709e+09  \n",
       "2          0.093632          0.414424  SITTING           2.0  1.438709e+09  \n",
       "3         -0.083428          0.147490  SITTING           2.0  1.438709e+09  \n",
       "4          0.083451         -0.049604  SITTING           2.0  1.438709e+09  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get a held out group of users\n",
    "# 2. increase the number of users in impersonal dataset\n",
    "# 3. accuracy on held out set should increase with increased users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
